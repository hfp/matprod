MATPROD - A LIBRARY FOR MATRIX MULTIPLICATION WITH OPTIONAL PIPELINING
          Documentation for Application Program Interface to Library Procedures

Copyright (C) 2013, 2014, 2017, 2018 Radford M. Neal.

  The matprod library is free software; you can redistribute it and/or modify
  it under the terms of the GNU General Public License as published by
  the Free Software Foundation; either version 2 of the License, or
  (at your option) any later version.

  This program is distributed in the hope that it will be useful,
  but WITHOUT ANY WARRANTY; without even the implied warranty of
  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  GNU General Public License for more details.

  You should have received a copy of the GNU General Public License along
  with this program; if not, write to the Free Software Foundation, Inc.,
  51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.


The matprod library provides double-precision real matrix/vector by
matrix/vector multiplication routines.  The motivating application is
implementation of matrix multiplication operators in a language such
as R, but the routines could also be used directly in an application
program.  Distinguishing features of this library are

   - Exact reproducibility between platforms, with the results being
     identical to what would be produced with a naive implementation.

   - No allocation of temporary storage (except, of course, for small
     amounts on the procedure-call stack, with only matprod_trans12
     allocating a significant amount, up to about 16K bytes).

   - Good performance, subject to the above two requirements.

   - Optional parallel implementation using the "helpers" library.

The routines should work with any C compiler implementing the C99
standard, and for any processor implementing IEEE standard
floating-point arithmetic.  However, some performance improvements are
enabled only for a gcc look-alike compiler, and SIMD instructions are
used only for Intel/AMD processors.  Performance tuning has been done
using gcc 7.2, and may not be optimal for other compilers.  Testing
has been primarily done on Intel/AMD machines, of a variety of
vintages.

Note that matrices are assumed to be stored in FORTRAN memory order,
proceeding down columns (not across rows).  To use the matprod
routines with matrices stored in standard C (row-major) order, just
reverse the order of the input operands (and exchange matprod_trans1
and matprod_trans2, as well as matprod_vec_mat and matprod_mat_vec).


Reproducibility.

These routines have been written to produce exactly the same results
as the obvious matrix multiplication algorithms, which sequentially
sum products of elements.  They can hence replace such naive
implementations without changing the results.  The results will also
be reproducible on different machines, provided all machines implement
IEEE standard double-precision floating point operations.  In
particular, these routines do not bypass multiplications by zero, and
therefore propagate Inf and NaN values properly.  They do not re-group
additions assuming associativity holds, so round-off errors and
overflows will be the same as for the obvious algorithms.

Note that producing the exact same result as the obvious algorithms
requires that the routines be built disabling any contraction of
floating-point operations (eg, fused multiply-add) that might be done
by the compiler/processor, and that all operations must be done with
64-bit floating-point numbers, without any extra precision for
intermediate results.

An unfortunate design choice in Intel/AMD processors will introduce
one source of non-reproducibility on platforms using them - when both
operands of a multiplication or addition are NaN values, one or the
other NaN is propagated, but it will be arbitrary which, because Intel
failed to ensure that addition and multiplication are commutative in
this situation, and C code has no control over the order of operands
in instructions generated by the compiler.


Parallel operation.

The matprod routines can be used via task procedures that can run in
"helper" threads, as supported by the helpers library (available at
https://github.com/radfordneal/helpers).

One option is to use a single helper thread for each matrix
multiplication operation, allowing this operation to exectute in
parallel with other operations done by the application (including
other matrix multiplication operations).  In many situations, the
output of one such operation can be pipledlined as the input for
another operation executing concurrently.

It is also possible to use more than one helper thread for a single
multiplication operation, perhaps while also pipelining its input or
output.


Performance.

These routines are written with a fair amount of attention to cache
performance and other efficiency issues.  Optional code is provided
that takes advantage of SSE2, SSE3, AVX, or AVX2 instructions on
Intel/AMD processors.  The routines can also optionally be built with
assumptions about alignment of arguments that may allow improved
performance.

Nevertheless, these routines may not be as fast as the matrix
multiplication routines in optimized BLAS libraries.  A general design
goal is for the non-parallel version of the routines to be no more
than a factor of two slower than the best non-parallel implementation
of matrix multiply (without the constraints on reproducibility).  This
goal is met for the most part.  For some operands, the matprod
routines are actually faster than the routines provided in some
optimized BLAS libraries, in some cases substantially faster.

See imp-doc and the comments in matprod.c and piped-matprod.c for
details on the algorithms used.


Building and using the procedures.

The non-parallel routines, in matprod.c, are called in ordinary C
fashion.  The parallel, pipelined routines, in piped-matprod.c, are
task procedures for use with the helpers library for parallel
computation (available at https://github.com/radfordneal/helpers).

The matprod.c and/or piped-matprod.c source files should be compiled
and linked with the program using the routines in the usual fashion.
Some options can be set by pre-processor symbols defined with
arguments to the compiler, or alternatively, by defining the symbol
MATPROD_APP_INCLUDED (as anything), which will cause the file
matprod-app.h to be included at the start of matprod.c and
piped-matprod.c, which may then define symbols that set these options.

These options include the following:

    ALIGN                If defined (must be a power of 2), the matprod
                         and piped_matprod functions will assume that
                         their arguments are aligned to such a
                         boundary (plus ALIGN_OFFSET, if defined).
                         This assumption may allow for faster and
                         smaller code.

    ALIGN_OFFSET         If ALIGN is defined, ALIGN_OFFSET gives the
                         offset from an even multiple of ALIGN that
                         arguments are aligned to.  It must be a
                         multiple of eight.  If ALIGN_OFFSET is not
                         defined, zero is assumed.

    NO_ASSUME_ALIGNED    If defined (as anything), the gcc builtin
                         function __builtin_assume_aligned, which
                         informs the compiler of alignment, will not
                         be used.  The matprod code may still use the
                         settings of ALIGN and ALIGN_OFFSET to
                         explicitly handle alignment.  This is meant
                         for performance testing, or for old gcc
                         versions without __builtin_assume_aligned.
                         It is not needed with a compiler that isn't
                         a gcc look-alike.

    MATPROD_NO_RESTRICT  If defined, the arguments of the matprod and
                         piped_matprod functions will not be declared
                         with the "restricted" keyword.  This is meant
                         for performance testing - results are not
                         guaranteed correct in any case if the output
                         argument aliases with an input.

Some special code has been written to take advantage of the SSE2,
SSE3, AVX, AVX2 instructions available on some Intel/AMD processors.
It is used only if gcc or a gcc look-alike is used, since this code
uses the builtin intrinsic functions that gcc provides.  This SIMD
code can be disabled by defining the symbol DISABLE_SIMD_CODE.  Just
the AVX or AVX2 code can be disabled by defining DISABLE_AVX_CODE (in
which case SSE2 or SSE3 code may still be used).  Some AVX or AVX2
code appears to not be better than the corresponding SSE2, SSE3, or
non-SIMD code; it is disabled unless the symbol ENABLE_ALL_AVX_CODE is
defined (and DISABLE_AVX_CODE is not defined).  The SIMD code sections
are automatically disabled when the routines are compiled for an
architecture without the required instructions.

Note that disabling the explicit SIMD code does not prevent the
compiler from generating SIMD instructions, if this is allowed by the
compiler options used.  Also note that depending on what architecture
the compiler is told to generate code for, intrinsics designed for
SSE2 may actually generate AVX instructions (and perhaps similarly for
SSE2/SSE3, SSE3/SSE4.1, AVX/AVX2, etc.).  However, code enabled for
only SSE2, or SSE3, or AVX should work on a processor having only the
specified level of SIMD instructions, if compiled for that processor.


Matrix operations using procedures in matprod.c.

The procedures below are in matprod.c, with declarations in matprod.h.
They are written with pointers declared as simply "double *", but, the
actual declaration will be "double * restrict" unless the matprod
source is compiled with -DMATPROD_NO_RESTRICT.  Note that the
dimensions of the matrices (numbers or rows and columns) have C int
type, but the total number of elements in a matrix may be larger than
can be stored in an int.

    void matprod_scalar_vec (double x, double *y, double *z, int m)

      Multiply scalar x and vector y, of dimension m, storing the
      result in vector z, of dimension m.

    double matprod_vec_vec (double *x, double *y, int k)

      Multiply row vector x and column vector y, both of dimension k,
      returning the result.

    void matprod_vec_mat (double *x, double *y, double *z, int k, int m)

      Multiply row vector x, of dimension k, and matrix y, of dimension
      k x m, storing the result in row vector z, of dimension m.

    void matprod_mat_vec (double *x, double *y, double *z, int n, int k)

      Multiply matrix x, of dimension n x k, and column vector y, of
      dimension k, storing the result in column vector z, of dimension n.

    void matprod_outer (double *x, double *y, double *z, int n, int m)

      Multiply the length-n column vector x (ie, n x 1 matrix) by the
      length-m row vector y (ie, 1 x m matrix), storing the result in
      the matrix z, of dimension n x m.

    void matprod_mat_mat (double *x, double *y, double *z, int n, int k, int m)

      Multiply matrix x, of dimension n x k, and matrix y, of
      dimension k x m, storing the result in matrix z, of dimension 
      n x m.

    void matprod_trans1 (double *x, double *y, double *z, int n, int k, int m)

      Multiply the transpose of matrix x, of dimension k x n, and
      matrix y, of dimension k x m, storing the result in matrix z, of
      dimension n x m.  If x and y are the same matrix, so the result
      is symetrical, redundant computations of symetric elements are
      avoided.

    void matprod_trans2 (double *x, double *y, double *z, int n, int k, int m)

      Multiply matrix x, of dimension n x k, and the transpose of
      matrix y, of dimension m x k, storing the result in matrix z, of
      dimension n x m.  If x and y are the same matrix, so the result
      is symetrical, redundant computations of symetric elements are
      avoided.

    void matprod_trans12 (double *x, double *y, double *z, int n, int k, int m)

      Multiply the transpose of matrix x, of dimension k x n, and the
      transpose of matrix y, of dimension m x k, storing the result in
      matrix z, of dimension n x m.

    void matprod_fill_lower (double *z, int n)

      Fills the lower triangle of the n x n matrix z with the symetric
      elements from the upper triangle.

For the above procedures, the result matrix, z, must have no overlap
with the operands, x and y.  However, the operands may be the same or
may overlap.

Some attention has been paid to making special cases of these routines
be fast.  Some cases where n, k, or m is 2, 3, or 4 are handled with
special code, when the general procedure would be significantly
slower.  Also, matprod_vec_mat and other procedures will simply call
matprod_scalar_vec when the operation reduces to multiplication by a
scalar.  Similarly,the matprod_outer procedure will be called from
matprod_mat_mat, matprod_trans1, matprod_trans2, and matprod_trans12
when the value of k passed is one.  Also, cases of matprod_mat_mat,
matprod_trans1, matprod_trans2, and matprod_trans12 that reduce to
matprod_vec_mat, or matprod_mat_vec will call the specialized routine,
and similarly cases of matprod_mat_vec and matprod_vec_mat that reduce
to matprod_vec_vec will call that routine.  Calling a specialized
routine directly will of course be slightly faster when it is known
that it is appropriate.


Parallel operation using procedures in piped-matprod.c.

Task procedures are defined in piped-matprod.c (and declared in
piped-matprod.h) for use with the "helpers" facility.  An operation
may be scheduled as a single task, potentially allowing it to run
concurrently with the master thread or other task procedures, perhaps
while pipelining data in or out, or several tasks may be scheduled for
a single operation, with each task computing a portion of the result
(again, perhaps with pipelining of data to/from other tasks), allowing
parallel computation for a single operation.  

Pipelining of the input may be done for the second operand for all
operations except matprod_trans2 and matprod_trans12.  Pipelining of
the output may be done for vector-matrix multiplies and matrix-matrix
multiplies except for matprod_trans12.  Note that, to reduce overhead,
columns or elements of pipelined output may not always be made
available immediately after being computed.

Using these routines requires the helpers.h and helpers.c files from
the helpers library, available at github.com/radfordneal/helpers.  A
helpers-app.h file must also be provided, which must contain the type
definitions required for the helpers routines, including a "pointer"
type for operands (which may or may not be an actual pointer).  The
helpers-app.h file must also define a LENGTH macro that returns the
number of elements in an operand or result matrix (equal to the number
of rows times the number of columns), and a REAL macro that returns a
pointer to the double-precision data for an operand or result matrix
(or these macros can instead be defined in a matprod-app.h file, which
is included if MATPROD_APP_INCLUDED is defined).

Note that the application will need to use the facilities provided by
the "helpers" package (eg, helpers_wait_until_not_being_computed) to
determine when the result of an operation is available.

The task procedures can be scheduled to run by the application, as
described below.  More typically, however, the par_matprod procedures
described below (also defined in piped-matprod.c and declared in
piped-matprod.h) will be used to schedule the appropriate tasks.


The par_matprod procedures.

The operands for the par_matprod procedures are of type helpers_var_t
(not direct pointers to the matrices).  The procedures all take a
"split" argument, which is the desired number of tasks to split the
operation into.  The actual number of tasks used might be less than
"split", if it seems that this will give better performance.  A
negative value can be used for "split", in which case the negative of
"split" will be used, with this value reduced only if that degree of
splitting is not possible (given implementation constraints).  A value
of zero for "split" indicates that the corresponding matprod procedure
should be called immediately without scheduling a task, after waiting
for the second operand to be computed if it has not been already.

The tasks scheduled by the par_matprod procedures use pipelining for
the second operand and the output, if this is possible. 

Note that the par_matprod procedures do not check for special cases
(for example, par_matprod_mat_mat does not check whether the operation
is actually a dot product doable with par_matprod_vec_vec).  These
special cases will instead be detected only after the task procedure
has started.  Accordingly, some non-negligible overhead can be avoided
if the appropriate par_matprod procedure is called originally.  Also,
the decisions taken regarding splitting into multiple tasks may not be
optimal for special cases.

The following par_matprod procedures are available:

    void par_matprod_vec_vec (helpers_var_ptr z, helpers_var_ptr x, 
                              helpers_var_ptr y, int split)

      Schedules a task to perform a vector-vector dot product, with
      pipelining of input y.  The result is stored in the scalar
      operand z.

    void par_matprod_vec_mat (helpers_var_ptr z, helpers_var_ptr x, 
                              helpers_var_ptr y, int split)

      Schedules a task to perform a vector-matrix product, with
      pipelining of input y and of the output.

    void par_matprod_mat_vec (helpers_var_ptr z, helpers_var_ptr x, 
                              helpers_var_ptr y, int split)

      Schedules a task to perform a matrix-vector product, with
      pipelining of input y, but not of the output.

    void par_matprod_outer (helpers_var_ptr z, helpers_var_ptr x, 
                            helpers_var_ptr y, int split)

      Schedules a task to perform a vector outer product, with
      pipelining of input y and of the output.

    void par_matprod_mat_mat (helpers_var_ptr z, helpers_var_ptr x, 
                              helpers_var_ptr y, int k, int split)

      Schedules a task to perform a matrix-matrix product, with k
      being the number of columns in x and rows in y, with pipelining
      of input y and of the output.

    void par_matprod_trans1 (helpers_var_ptr z, helpers_var_ptr x, 
                             helpers_var_ptr y, int k, int split)

      Schedules a task to perform a matrix-matrix product with first
      operand transposed, with k being the number of rows in x and y,
      with pipelining of input y and of the output.

    void par_matprod_trans2 (helpers_var_ptr z, helpers_var_ptr x, 
                             helpers_var_ptr y, int k, int split)

      Schedules a task to perform a matrix-matrix product with second
      operand transposed, with k being the number of columns in x and
      y, with pipelining of the output, but not of the input.

    void par_matprod_trans12 (helpers_var_ptr z, helpers_var_ptr x, 
                             helpers_var_ptr y, int k, int split)

      Schedules a task to perform a matrix-matrix product with both
      operands transposed, with k being the number of rows in x and
      columns in y, with no pipelining of either input or output.


Task procedures.

An application can instead do its own scheduling of task procedures,
though this should generally be unnecessary.  These task procedures
are declared in piped-matprod.h to be of type helpers_task_proc, for
which the arguments are an op value, a pointer to the result matrix
(which is possibly a vector or scalar), a pointer to the first operand
matrix/vector, and a pointer to the second operand matrix/vector.

When an operation is to be done by a single task, the op value passed
to the task procedure should be zero except for the mat_mat, trans1,
trans2, and trans12 procedures, for which it should be the value of k
(the number of products summed to compute each element of the result).

When an operation is to be split between several tasks, the low 32
bits of the op value should be the value of k (or zero, for tasks not
requiring k), the 8 bits above that should be the number of tasks used
for the operation minus one, and the 8 bits above that should be the
portion (numbered from zero) that this task does.  The tasks should be
scheduled scheduled sequentially starting with the one doing portion
zero, with pipelining of each task's output to the next task's output
operand.  They may also be scheduled with pipelining of the second
input (but this has no effect for matprod_trans2 and matprod_trans12).

The task procedures (found in piped-matprod.c) correspond to the
non-pipelined procedures above, and are as follows:

    task_piped_matprod_vec_vec

      Vector-vector multiply, with element-by-element pipelining of
      the second operand.

    task_piped_matprod_vec_mat

      Vector-matrix multiply, with column-by-column pipelining of the
      second operand, and element-by-element pipelining of the output.

    task_piped_matprod_mat_vec

      Matrix-vector multiply, with element-by-element pipelining of
      the second operand.

    task_piped_matprod_outer

      Matrix outer product of column vector and row vector, with
      element-by-element pipelining of the second operand, and
      column-by-column pipelining of the output.

    task_piped_matprod_mat_mat

      Matrix-matrix multiply, with column-by-column pipelining of the
      second operand, and column-by-column pipelining of the output.

    task_piped_matprod_trans1

      Multiplies the transpose of first operand matrix and the second
      operand matrix, with column-by-column pipelining of the second
      operand, and column-by-column pipelining of the output.

    task_piped_matprod_trans2

      Multiplies the first operand matrix and the transpose of the
      second operand matrix, with column-by-column pipelining of the
      output, but no pipelining of the operands.  (However, this task
      procedure does explicitly wait for the second operand to become
      available, in case it has been scheduled with pipelining of this
      operand, since it is pipelined for many of the other task
      procedures.)

    task_piped_matprod_trans12

      Multiplies the transpose of the first operand matrix and the
      transpose of the second operand matrix, with no pipelining of
      the output and no pipelining of the operands.  (However, this
      task procedure does explicitly wait for the second operand to
      become available, in case it has been scheduled with pipelining
      of this operand, since it is pipelined for many of the other
      task procedures.)
